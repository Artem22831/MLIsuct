{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Для многих задач связанные с текстом нам бы хотелось представлять текст в виде вектора, чтобы похожие слова или предложения располагались рядом с друг другом. Для чего это нужно?. Например для задач поиска, нам хотелось бы выдавать ответ так, чтобы наиболее похожие статьи находились в верху списка. Такой тип представления текстов и слов называется дистрибутивная семантика.</p> \n",
    "<p>Каким же образом мы можем представить слова в таком виде?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Логичным методом представления слова является, контекст в котором оно употребляются в тексте</p>\n",
    "<p>Контекстом мы будем считать слова, которые находятся рядом с искомым словом в окне определенного размера, например для слова <i>лес</i> и окна 3, контекст выглядит следующим образом</p>\n",
    "<p>Житель <b>местности, покрытой хвойным</b> <i>лесом</i>, <b>связывает с «деревом»</b> прежде всего образ ели или сосны.</p>\n",
    "<p>Исходя из этой идеи, мы можем посчитать вектор слова следующим образом</p>\n",
    "\n",
    "- Посчитать слова которые встречаются с данным словом в одном контексте\n",
    "- Создать вектор где в определенное значение записана частота определенного слова из словаря\n",
    "\n",
    "<p>В таком случае похожесть между словами мы можем измерять с помощью косинусного расстояния между их векторами</p>\n",
    "<p>Однако такой способ имеет большой недостаток, а именно часто встречаемые слова (например предлоги) будут иметь очень большой вес. Чтобы уменьшить влияние таких слов, вместо частоты встречаемости слов, будем считать PMI (pointwise mutual information)</p>\n",
    "<p><center>$\\large{PMI = \\log{\\frac{p(u, v)}{p(v)p(u)}}=\\log{\\frac{n_{uv}n}{n_un_v}}}$</center></p>\n",
    "<p>Однако из с данным способом представления встречаемости слов есть проблема, для редко встречаемых между собой слов получается большое отрицательно значение, а если слова никогда не встречаются между собой то значение равно $-\\infty$. Поэтому на практике пользуются pPMI</p>\n",
    "<p><center>$\\large{pPMI = \\max{(0, PMI)}}$</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>И так у нас имеется способ представление совстречаемости слов с помощью pPMI. Так же мы можем мерить похожесть слов между собой с помощью косинусного расстояния. Однако у нас есть другая проблема а именно, размерность вектора каждого слова равна длинне словаря и затраты на вычисление похожести слов слишком большие. Поэтому воспользуюмся техникой снижения размерности а именно SVD</p>\n",
    "<p>SVD представляет нашу матрицу размера (W*W) в виде произведения двух матриц (W*K) и (K*W)</p>\n",
    "<img src=\"./img/pmi_svd.png\", style=\"width: 500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
